{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e4dde8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed210f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/working-env-1/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Google Library\n",
    "# from google import genai\n",
    "# import google.generativeai as genai\n",
    "# from google.genai import types\n",
    "\n",
    "import sys\n",
    "from pydantic import BaseModel\n",
    "import mimetypes\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import pipeline\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import csv\n",
    "import urllib.request\n",
    "import imagehash\n",
    "import open_clip\n",
    "import faiss\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1e5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the meme jsonl file\n",
    "with open('data/merged_parsed_results.jsonl', 'r') as f:\n",
    "    meme_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Loading meme metadata\n",
    "meme_metadata = pd.read_parquet('data/meme_submissions.zst.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fbaf9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of memes instancesloaded: 172573\n",
      "meme_submissions_1107342\n",
      "meme_submissions_1044848\n",
      "Number of normal memes: 171793\n",
      "Number of memes after filtering NON_MEME: 171793\n"
     ]
    }
   ],
   "source": [
    "print('Number of memes instancesloaded:', len(meme_data))\n",
    "\n",
    "# Number of non-memes\n",
    "i = 0\n",
    "for meme in meme_data:\n",
    "    try:\n",
    "        if meme['data']['template'] not in [\"NON_MEME\", \"NO_MEME\"]:\n",
    "            i += 1\n",
    "    except:\n",
    "        print(meme['key'])\n",
    "print('Number of normal memes:', i)\n",
    "\n",
    "# Filtering out non-memes\n",
    "meme_data = [meme for meme in meme_data if isinstance(meme['data'], dict)]\n",
    "meme_data = [meme for meme in meme_data if meme['data'].get('template') not in [\"NON_MEME\", \"NO_MEME\"]]\n",
    "print('Number of memes after filtering NON_MEME:', len(meme_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cf4edb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>template</th>\n",
       "      <th>global_context_description</th>\n",
       "      <th>local_context_user_texts</th>\n",
       "      <th>local_context_text_meaning</th>\n",
       "      <th>local_context_instance_specific_image_description</th>\n",
       "      <th>global_context_keywords</th>\n",
       "      <th>local_context_keywords</th>\n",
       "      <th>local_context_global_context_keywords</th>\n",
       "      <th>local_context_local_context_keywords</th>\n",
       "      <th>local_context_made with mematic</th>\n",
       "      <th>local_context_template</th>\n",
       "      <th>local_context_made_with_mematic</th>\n",
       "      <th>local_context_template_modification</th>\n",
       "      <th>local_context_template_text</th>\n",
       "      <th>local_context_watermark</th>\n",
       "      <th>local_context_title</th>\n",
       "      <th>local_context_meme_template_overlay</th>\n",
       "      <th>global_context_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meme_submissions_1343519</td>\n",
       "      <td>NO_TEMPLATE</td>\n",
       "      <td>A cat with a loading symbol on its forehead, l...</td>\n",
       "      <td>[Hitler when he saw a blue-eyed Jew]</td>\n",
       "      <td>The meme humorously depicts Hitler's supposed ...</td>\n",
       "      <td></td>\n",
       "      <td>[cat, loading symbol, confusion, distress, meme]</td>\n",
       "      <td>[Hitler, blue-eyed Jew, confusion, ideology, l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meme_submissions_134352</td>\n",
       "      <td>I fear no man. But that thing... it scares me.</td>\n",
       "      <td>A three-panel meme format. The first panel sho...</td>\n",
       "      <td>[]</td>\n",
       "      <td>The meme humorously depicts a character who cl...</td>\n",
       "      <td>The second panel contains an image of several ...</td>\n",
       "      <td>[fear, unscared, scared, meme format, character]</td>\n",
       "      <td>[bouncy balls, marbles, fear, irrational fear,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meme_submissions_1343524</td>\n",
       "      <td>NO_TEMPLATE</td>\n",
       "      <td>A comparison meme showing two fictional creatu...</td>\n",
       "      <td>[]</td>\n",
       "      <td>The meme highlights the similarities between t...</td>\n",
       "      <td></td>\n",
       "      <td>[comparison, creatures, minecraft, stranger th...</td>\n",
       "      <td>[warden, demogorgon, comparison, similarities,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meme_submissions_1343526</td>\n",
       "      <td>Homer Simpson \"Something so stupid\"</td>\n",
       "      <td>A four-panel meme format featuring Homer Simps...</td>\n",
       "      <td>[Increase carbon filtering, produce more wind ...</td>\n",
       "      <td>The meme criticizes the perceived ineffectiven...</td>\n",
       "      <td></td>\n",
       "      <td>[Homer Simpson, The Simpsons, stupid action, s...</td>\n",
       "      <td>[carbon filtering, windmills, stupid, species,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meme_submissions_134353</td>\n",
       "      <td>NO_TEMPLATE</td>\n",
       "      <td>The meme shows a comparison between a house co...</td>\n",
       "      <td>[My house coat in the morning vs my house coat...</td>\n",
       "      <td>The meme humorously exaggerates the difference...</td>\n",
       "      <td>The image is split into two parts. The top tex...</td>\n",
       "      <td>[house coat, morning, night, comparison, humor...</td>\n",
       "      <td>[house coat, morning, 3am, monster, creepy, co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        key                                        template  \\\n",
       "0  meme_submissions_1343519                                     NO_TEMPLATE   \n",
       "1   meme_submissions_134352  I fear no man. But that thing... it scares me.   \n",
       "2  meme_submissions_1343524                                     NO_TEMPLATE   \n",
       "3  meme_submissions_1343526             Homer Simpson \"Something so stupid\"   \n",
       "4   meme_submissions_134353                                     NO_TEMPLATE   \n",
       "\n",
       "                          global_context_description  \\\n",
       "0  A cat with a loading symbol on its forehead, l...   \n",
       "1  A three-panel meme format. The first panel sho...   \n",
       "2  A comparison meme showing two fictional creatu...   \n",
       "3  A four-panel meme format featuring Homer Simps...   \n",
       "4  The meme shows a comparison between a house co...   \n",
       "\n",
       "                            local_context_user_texts  \\\n",
       "0               [Hitler when he saw a blue-eyed Jew]   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  [Increase carbon filtering, produce more wind ...   \n",
       "4  [My house coat in the morning vs my house coat...   \n",
       "\n",
       "                          local_context_text_meaning  \\\n",
       "0  The meme humorously depicts Hitler's supposed ...   \n",
       "1  The meme humorously depicts a character who cl...   \n",
       "2  The meme highlights the similarities between t...   \n",
       "3  The meme criticizes the perceived ineffectiven...   \n",
       "4  The meme humorously exaggerates the difference...   \n",
       "\n",
       "   local_context_instance_specific_image_description  \\\n",
       "0                                                      \n",
       "1  The second panel contains an image of several ...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  The image is split into two parts. The top tex...   \n",
       "\n",
       "                             global_context_keywords  \\\n",
       "0   [cat, loading symbol, confusion, distress, meme]   \n",
       "1   [fear, unscared, scared, meme format, character]   \n",
       "2  [comparison, creatures, minecraft, stranger th...   \n",
       "3  [Homer Simpson, The Simpsons, stupid action, s...   \n",
       "4  [house coat, morning, night, comparison, humor...   \n",
       "\n",
       "                              local_context_keywords  \\\n",
       "0  [Hitler, blue-eyed Jew, confusion, ideology, l...   \n",
       "1  [bouncy balls, marbles, fear, irrational fear,...   \n",
       "2  [warden, demogorgon, comparison, similarities,...   \n",
       "3  [carbon filtering, windmills, stupid, species,...   \n",
       "4  [house coat, morning, 3am, monster, creepy, co...   \n",
       "\n",
       "  local_context_global_context_keywords local_context_local_context_keywords  \\\n",
       "0                                   NaN                                  NaN   \n",
       "1                                   NaN                                  NaN   \n",
       "2                                   NaN                                  NaN   \n",
       "3                                   NaN                                  NaN   \n",
       "4                                   NaN                                  NaN   \n",
       "\n",
       "  local_context_made with mematic local_context_template  \\\n",
       "0                             NaN                    NaN   \n",
       "1                             NaN                    NaN   \n",
       "2                             NaN                    NaN   \n",
       "3                             NaN                    NaN   \n",
       "4                             NaN                    NaN   \n",
       "\n",
       "  local_context_made_with_mematic local_context_template_modification  \\\n",
       "0                             NaN                                 NaN   \n",
       "1                             NaN                                 NaN   \n",
       "2                             NaN                                 NaN   \n",
       "3                             NaN                                 NaN   \n",
       "4                             NaN                                 NaN   \n",
       "\n",
       "  local_context_template_text local_context_watermark local_context_title  \\\n",
       "0                         NaN                     NaN                 NaN   \n",
       "1                         NaN                     NaN                 NaN   \n",
       "2                         NaN                     NaN                 NaN   \n",
       "3                         NaN                     NaN                 NaN   \n",
       "4                         NaN                     NaN                 NaN   \n",
       "\n",
       "  local_context_meme_template_overlay global_context_thought  \n",
       "0                                 NaN                    NaN  \n",
       "1                                 NaN                    NaN  \n",
       "2                                 NaN                    NaN  \n",
       "3                                 NaN                    NaN  \n",
       "4                                 NaN                    NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Turn meme_data from an array of jsons into a Dataframe for better visuals ===\n",
    "from pandas import json_normalize\n",
    "meme_data_df = pd.DataFrame(meme_data)\n",
    "meme_data_df = json_normalize(\n",
    "    meme_data,\n",
    "    sep=\"_\",\n",
    "    meta=[\"key\"],\n",
    "    record_path=None\n",
    ")\n",
    "\n",
    "# Remove the leading \"_data\"\n",
    "meme_data_df.columns = meme_data_df.columns.str.replace(\"data_\", \"\", regex=False)\n",
    "meme_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66808d83",
   "metadata": {},
   "source": [
    "## More than half of annotated templates are `NO_TEMPLATE`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f867ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'NO_TEMPLATE' assigned memes: 91958\n",
      "Number of assigned templates memes: 79835\n",
      "\"NO_TEMPLATE\" data contains  53.53% of the entire data after the filter\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_template_df = meme_data_df[meme_data_df['template'] == 'NO_TEMPLATE']\n",
    "template_df = meme_data_df[meme_data_df['template'] != 'NO_TEMPLATE']\n",
    "\n",
    "# Ratio of memes that were considered NO_TEMPLATE to the entire data\n",
    "ratio_no_template = no_template_df.shape[0] / meme_data_df.shape[0] * 100\n",
    "print(f\"Number of 'NO_TEMPLATE' assigned memes: {no_template_df.shape[0]}\")\n",
    "print(f\"Number of assigned templates memes: {template_df.shape[0]}\")\n",
    "print(f'\"NO_TEMPLATE\" data contains {ratio_no_template: .2f}% of the entire data after the filter')\n",
    "\n",
    "# Plot the distribution of templates\n",
    "sizes = [no_template_df.shape[0], template_df.shape[0]]\n",
    "labels = [\"NO_TEMPLATE\", \"Has template\"]\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie(sizes, labels=labels, autopct=\"%1.1f%%\", startangle=90)\n",
    "plt.title(\"Template coverage\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# import matplotlib.pyplot as plt\n",
    "# tpl_counts = meme_data_df[\"template\"].dropna().value_counts()\n",
    "\n",
    "# top_k = 20\n",
    "# top = tpl_counts.head(top_k)\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# top.sort_values().plot(kind=\"barh\")\n",
    "# plt.title(f\"Top {top_k} templates\")\n",
    "# plt.xlabel(\"Count\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d319f1ff",
   "metadata": {},
   "source": [
    "## 1. Template Reassignment for `NO_TEMPLATE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NO_TEMPLATE to see if it is actually templateless, if not, no problem, but if yes we can assign based on clustering/reference set\n",
    "img_ids = no_template_df[\"key\"].astype(str).sample(n=10, random_state=42).to_list()\n",
    "\n",
    "# Perform Binary Search in order to search images with \"NO_TEMPLATE\"\n",
    "from pathlib import Path\n",
    "import bisect\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "folder = Path(\"Reddit2024_nolabel/images\")\n",
    "\n",
    "# Extract numeric attr for each image's id. \n",
    "# e.g.  we extract 1343519 from 'meme_submissions_1343519' \n",
    "def extract_num(img_ids):\n",
    "    return int(img_ids.rsplit(\"_\", 1)[1])\n",
    "\n",
    "\n",
    "# Build an index from files in folder (supports any extension)\n",
    "# Example file: meme_submissions_1343519.jpg\n",
    "id_to_paths = {}\n",
    "for p in folder.iterdir():\n",
    "    if not p.is_file():\n",
    "        continue\n",
    "    stem = p.stem  # removes extension\n",
    "    if stem.startswith(\"meme_submissions_\"):\n",
    "        try:\n",
    "            n = extract_num(stem)\n",
    "            id_to_paths.setdefault(n, []).append(p)  # keep all matches\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "sorted_ids = sorted(id_to_paths.keys())\n",
    "\n",
    "def bs_find_image_paths(meme_id_str: str):\n",
    "    q = extract_num(meme_id_str)\n",
    "    i = bisect.bisect_left(sorted_ids, q)\n",
    "    if i < len(sorted_ids) and sorted_ids[i] == q:\n",
    "        return id_to_paths[q]   # list of matching file paths\n",
    "    return []\n",
    "\n",
    "\n",
    "# # Print out image path after performing Binary Search\n",
    "# for id in img_ids:\n",
    "#     paths = bs_find_image_paths(id)\n",
    "#     print(id, \"->\", paths if paths else \"Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2001fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "def show_paths(paths, cols=4, figsize_per_row=4):\n",
    "    if not paths:\n",
    "        print(\"No images found.\")\n",
    "        return\n",
    "    n = len(paths)\n",
    "    rows = ceil(n / cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * figsize_per_row, rows * figsize_per_row))\n",
    "    axes = axes.flatten() if hasattr(axes, \"flatten\") else [axes]\n",
    "\n",
    "    for ax, p in zip(axes, paths):\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(p.stem, fontsize=8)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for ax in axes[n:]:\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# # dynamic: gather from your keys + lookup\n",
    "# img_ids = no_template_df[\"key\"].astype(str).str.strip().head(20).tolist()\n",
    "\n",
    "found_paths = []\n",
    "missing_ids = []\n",
    "\n",
    "for k in img_ids:\n",
    "    paths = bs_find_image_paths(k)   # returns [] or list[Path]\n",
    "    if paths:\n",
    "        found_paths.extend(paths)\n",
    "    else:\n",
    "        missing_ids.append(k)\n",
    "\n",
    "print(f\"Found: {len(found_paths)} | Missing: {len(missing_ids)}\")\n",
    "if missing_ids:\n",
    "    print(\"Missing examples:\", missing_ids[:5])\n",
    "\n",
    "show_paths(found_paths, cols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b10d1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['key', 'template', 'global_context_description',\n",
       "       'local_context_user_texts', 'local_context_text_meaning',\n",
       "       'local_context_instance_specific_image_description',\n",
       "       'global_context_keywords', 'local_context_keywords',\n",
       "       'local_context_global_context_keywords',\n",
       "       'local_context_local_context_keywords',\n",
       "       'local_context_made with mematic', 'local_context_template',\n",
       "       'local_context_made_with_mematic',\n",
       "       'local_context_template_modification', 'local_context_template_text',\n",
       "       'local_context_watermark', 'local_context_title',\n",
       "       'local_context_meme_template_overlay', 'global_context_thought'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c179bcae",
   "metadata": {},
   "source": [
    "### 1.1. Template Reassignment using `Images`\n",
    "#### Plan\n",
    "1. **Manually inspect sample images**\n",
    "   - Review a subset of images from the dataset to validate labeling quality.\n",
    "\n",
    "2. **Build a reference set from labeled templates**\n",
    "   - Use images with an existing template label.\n",
    "   - Compute **CLIP embeddings** and **pHash**.\n",
    "   - Store results in a separate reference table.\n",
    "\n",
    "3. **Match `NO_TEMPLATE` images**\n",
    "   - Compute CLIP embeddings and pHash for each `NO_TEMPLATE` image.\n",
    "   - Retrieve top candidate matches from the reference set.\n",
    "\n",
    "4. **Apply decision rules**\n",
    "   - If `phash_dist <= 6`, assign that template (**high confidence**).\n",
    "   - Else if `clip_cos >= 0.86` and `(top1 - top2) >= 0.03`, assign that template.\n",
    "   - Else, keep `NO_TEMPLATE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e574ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import torch\n",
    "import open_clip\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "try:\n",
    "    import faiss\n",
    "    HAS_FAISS = True\n",
    "except Exception:\n",
    "    HAS_FAISS = False\n",
    "\n",
    "KEY_COL = \"key\"\n",
    "LABEL_COL = \"template\"\n",
    "NO_TEMPLATE = \"NO_TEMPLATE\"\n",
    "\n",
    "# Adjust if needed:\n",
    "IMAGE_DIR = Path(\"Reddit2024_nolabel/images\")  \n",
    "\n",
    "# HYPERPARAMS for pHash and CLIP\n",
    "PHASH_MAX = 6\n",
    "CLIP_MIN = 0.86\n",
    "MARGIN_MIN = 0.03\n",
    "TOPK = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b808f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "exts = '.jpg'\n",
    "stem_to_path = {\n",
    "    p.stem.strip(): p\n",
    "    for p in IMAGE_DIR.iterdir()\n",
    "    if p.is_file() and p.suffix.lower() == exts\n",
    "}\n",
    "\n",
    "work_df = meme_data_df.copy()\n",
    "work_df[KEY_COL] = work_df[KEY_COL].astype(str).str.strip()\n",
    "work_df[\"image_path\"] = work_df[KEY_COL].map(stem_to_path)\n",
    "\n",
    "print(\"Total rows:\", len(work_df))\n",
    "print(\"Rows with image path:\", work_df[\"image_path\"].notna().sum())\n",
    "print(\"Missing image path:\", work_df[\"image_path\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d9c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = work_df[work_df[\"image_path\"].notna()].copy()\n",
    "\n",
    "known_df = valid_df[valid_df[LABEL_COL] != NO_TEMPLATE].copy()\n",
    "unknown_df = valid_df[valid_df[LABEL_COL] == NO_TEMPLATE].copy()\n",
    "\n",
    "print(\"Known templates:\", len(known_df))\n",
    "print(\"NO_TEMPLATE:\", len(unknown_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.mps.is_available() else \"cpu\" # \"mps\" since I use Mac, else \"cuda\"\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    \"ViT-B-32\", pretrained=\"laion2b_s34b_b79k\"\n",
    ")\n",
    "model = model.to(device).eval()\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10276e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def clip_embed(path: Path) -> np.ndarray:\n",
    "    img = preprocess(Image.open(path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "    vec = model.encode_image(img)\n",
    "    vec = vec / vec.norm(dim=-1, keepdim=True)\n",
    "    return vec.cpu().numpy().astype(\"float32\")[0]\n",
    "\n",
    "def phash_val(path: Path):\n",
    "    return imagehash.phash(Image.open(path).convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_rows = []\n",
    "for r in tqdm(known_df.itertuples(index=False), total=len(known_df), desc=\"Building reference\"):\n",
    "    try:\n",
    "        p = Path(r.image_path)\n",
    "        ref_rows.append({\n",
    "            KEY_COL: getattr(r, KEY_COL),\n",
    "            LABEL_COL: getattr(r, LABEL_COL),\n",
    "            \"image_path\": p,\n",
    "            \"phash\": phash_val(p),\n",
    "            \"clip\": clip_embed(p),\n",
    "        })\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "reference_df = pd.DataFrame(ref_rows)\n",
    "print(\"Reference rows:\", len(reference_df))\n",
    "reference_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CLIP Search Index\n",
    "ref_vecs = np.stack(reference_df[\"clip\"].values).astype(\"float32\")\n",
    "ref_labels = reference_df[LABEL_COL].values\n",
    "\n",
    "if HAS_FAISS:\n",
    "    index = faiss.IndexFlatIP(ref_vecs.shape[1])  # cosine if normalized\n",
    "    index.add(ref_vecs)\n",
    "    print(\"Using FAISS\")\n",
    "else:\n",
    "    print(\"FAISS not available, using NumPy fallback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103669e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_clip(query_vec: np.ndarray, k=TOPK):\n",
    "    q = query_vec[None, :].astype(\"float32\")\n",
    "    if HAS_FAISS:\n",
    "        sims, idxs = index.search(q, k)\n",
    "        return sims[0], idxs[0]\n",
    "    sims = ref_vecs @ q[0]  # cosine (normalized vectors)\n",
    "    idxs = np.argsort(-sims)[:k]\n",
    "    return sims[idxs], idxs\n",
    "\n",
    "def assign_template(path: Path):\n",
    "    # pHash pass\n",
    "    qh = phash_val(path)\n",
    "    ph_dists = reference_df[\"phash\"].map(lambda h: qh - h).values\n",
    "    best_i = int(np.argmin(ph_dists))\n",
    "    best_ph = int(ph_dists[best_i])\n",
    "    best_ph_label = reference_df.iloc[best_i][LABEL_COL]\n",
    "\n",
    "    if best_ph <= PHASH_MAX:\n",
    "        return {\n",
    "            \"new_template\": best_ph_label,\n",
    "            \"match_method\": \"phash\",\n",
    "            \"confidence\": 1.0 - best_ph / 64.0,\n",
    "            \"phash_dist\": best_ph,\n",
    "            \"clip_top1\": np.nan,\n",
    "            \"clip_margin\": np.nan,\n",
    "        }\n",
    "\n",
    "    # CLIP pass\n",
    "    qv = clip_embed(path)\n",
    "    sims, idxs = topk_clip(qv, TOPK)\n",
    "    top1 = float(sims[0])\n",
    "    top2 = float(sims[1]) if len(sims) > 1 else -1.0\n",
    "    margin = top1 - top2\n",
    "    label1 = reference_df.iloc[int(idxs[0])][LABEL_COL]\n",
    "\n",
    "    if top1 >= CLIP_MIN and margin >= MARGIN_MIN:\n",
    "        return {\n",
    "            \"new_template\": label1,\n",
    "            \"match_method\": \"clip\",\n",
    "            \"confidence\": top1,\n",
    "            \"phash_dist\": best_ph,\n",
    "            \"clip_top1\": top1,\n",
    "            \"clip_margin\": margin,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"new_template\": NO_TEMPLATE,\n",
    "        \"match_method\": \"none\",\n",
    "        \"confidence\": top1,\n",
    "        \"phash_dist\": best_ph,\n",
    "        \"clip_top1\": top1,\n",
    "        \"clip_margin\": margin,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eaaefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for r in tqdm(unknown_df.itertuples(index=False), total=len(unknown_df), desc=\"Matching NO_TEMPLATE\"):\n",
    "    try:\n",
    "        p = Path(r.image_path)\n",
    "        out = assign_template(p)\n",
    "        out[KEY_COL] = getattr(r, KEY_COL)\n",
    "        preds.append(out)\n",
    "    except Exception:\n",
    "        preds.append({\n",
    "            KEY_COL: getattr(r, KEY_COL),\n",
    "            \"new_template\": NO_TEMPLATE,\n",
    "            \"match_method\": \"error\",\n",
    "            \"confidence\": np.nan,\n",
    "            \"phash_dist\": np.nan,\n",
    "            \"clip_top1\": np.nan,\n",
    "            \"clip_margin\": np.nan,\n",
    "        })\n",
    "\n",
    "pred_df = pd.DataFrame(preds)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MERGE WITH THE ORIGINAL DF COPIED TO GET THE NEW_TEMPLATE\n",
    "image_reassigned_df = meme_data_df.copy()\n",
    "tmp = image_reassigned_df.merge(\n",
    "    pred_df[[\"key\", \"new_template\"]], \n",
    "    on=\"key\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "tmp[\"template\"] = tmp[\"new_template\"].combine_first(tmp[\"template\"])\n",
    "\n",
    "\n",
    "tmp = tmp.drop(columns=[\"new_template\"])\n",
    "\n",
    "# result\n",
    "image_reassigned_df_updated = tmp\n",
    "image_reassigned_df_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7306fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS AFTER ASSIGNING NEW TEMPLATES\n",
    "no_template_df = image_reassigned_df_updated[image_reassigned_df_updated['template'] == 'NO_TEMPLATE']\n",
    "template_df = image_reassigned_df_updated[image_reassigned_df_updated['template'] != 'NO_TEMPLATE']\n",
    "\n",
    "# Ratio of memes that were considered NO_TEMPLATE to the entire data\n",
    "ratio_no_template = no_template_df.shape[0] / meme_data_df.shape[0] * 100\n",
    "print(f\"Number of 'NO_TEMPLATE' assigned memes atfer reassigning: {no_template_df.shape[0]}\")\n",
    "print(f\"Number of assigned templates memes: {template_df.shape[0]}\")\n",
    "print(f'\"NO_TEMPLATE\" data contains {ratio_no_template: .2f}% of the entire data after the reassignment')\n",
    "\n",
    "# Plot the distribution of templates\n",
    "sizes = [no_template_df.shape[0], template_df.shape[0]]\n",
    "labels = [\"NO_TEMPLATE\", \"Has template\"]\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie(sizes, labels=labels, autopct=\"%1.1f%%\", startangle=90)\n",
    "plt.title(\"Template coverage\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c9f57c",
   "metadata": {},
   "source": [
    "### 1.2. Template reassignment using `global context + text + desc`\n",
    "\n",
    "#### Plan\n",
    "1. **Build text features**\n",
    "   - Create `text_for_embed` by concatenating:\n",
    "     - `global_context_description`\n",
    "     - `global_context_keywords` (join array into a string)\n",
    "     - `global_context_thought`\n",
    "\n",
    "2. **Embed the text**\n",
    "   - Encode `text_for_embed` for both labeled templates and `NO_TEMPLATE` memes using a sentence embedding model (e.g., `all-mpnet-base-v2`).\n",
    "   - Normalize embeddings for cosine similarity.\n",
    "\n",
    "3. **Compute template centroids**\n",
    "   - Group labeled memes by `template`.\n",
    "   - Average embeddings within each template to form a centroid vector.\n",
    "\n",
    "4. **Match `NO_TEMPLATE` to centroids**\n",
    "   - Compute cosine similarity from each `NO_TEMPLATE` meme to all centroids.\n",
    "   - Store `top1_sim`, `top2_sim`, and `margin = top1_sim - top2_sim`.\n",
    "\n",
    "5. **Apply decision rules**\n",
    "   - If `top1_sim >= SIM_MIN` and `margin >= MARGIN_MIN`, assign `new_template`.\n",
    "   - Else, keep `NO_TEMPLATE`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e0a52",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d997de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD TEXT ROW\n",
    "\n",
    "\n",
    "KEY_COL = \"key\"\n",
    "LABEL_COL = \"template\"\n",
    "NO_TEMPLATE = \"NO_TEMPLATE\"\n",
    "\n",
    "TEXT_COLS = [\n",
    "    \"global_context_description\",\n",
    "    \"global_context_keywords\",   # list\n",
    "    \"global_context_thought\",\n",
    "]\n",
    "\n",
    "def build_text(row):\n",
    "    parts = []\n",
    "    for c in TEXT_COLS:\n",
    "        v = row.get(c, None)\n",
    "\n",
    "        # handle keyword arrays\n",
    "        if isinstance(v, list):\n",
    "            s = \" \".join([str(x).strip() for x in v if x is not None and str(x).strip()])\n",
    "        else:\n",
    "            if v is None or pd.isna(v):\n",
    "                continue\n",
    "            s = str(v).strip()\n",
    "\n",
    "        if s:\n",
    "            parts.append(s)\n",
    "\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "work_df = meme_data_df.copy()\n",
    "work_df[\"text_for_embed\"] = work_df.apply(build_text, axis=1)\n",
    "work_df = work_df[work_df[\"text_for_embed\"].str.len() > 0].copy()\n",
    "\n",
    "print(\"Rows with usable text:\", len(work_df))\n",
    "print(\"NO_TEMPLATE rows:\", (work_df[LABEL_COL] == NO_TEMPLATE).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ba7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_df = work_df[work_df[LABEL_COL] != NO_TEMPLATE].copy().reset_index(drop=True)\n",
    "unknown_df = work_df[work_df[LABEL_COL] == NO_TEMPLATE].copy().reset_index(drop=True)\n",
    "def fix_template(x):\n",
    "    if isinstance(x, list):\n",
    "        return x[0] if len(x) > 0 else None\n",
    "    return x\n",
    "\n",
    "# Make sure templates are hashable strings\n",
    "known_df = known_df.copy()\n",
    "unknown_df = unknown_df.copy()\n",
    "known_df[LABEL_COL] = known_df[LABEL_COL].apply(fix_template)\n",
    "unknown_df[LABEL_COL] = unknown_df[LABEL_COL].apply(fix_template)\n",
    "\n",
    "print(\"Known:\", len(known_df), \"Unknown:\", len(unknown_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87486f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text + build templates\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# Encode both\n",
    "known_emb = model.encode(\n",
    "    known_df[\"text_for_embed\"].tolist(),\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "unknown_emb = model.encode(\n",
    "    unknown_df[\"text_for_embed\"].tolist(),\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167dbf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = known_df.groupby(LABEL_COL).indices  # template -> row indices\n",
    "templates = []\n",
    "centroids = []\n",
    "\n",
    "for t, idxs in grp.items():\n",
    "    c = known_emb[list(idxs)].mean(axis=0)\n",
    "    c = c / np.linalg.norm(c)\n",
    "    templates.append(t)\n",
    "    centroids.append(c)\n",
    "\n",
    "centroids = np.vstack(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de02ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the NO_TEMPLATE by cosine_similarity\n",
    "sims = cosine_similarity(unknown_emb, centroids)\n",
    "top1_idx = sims.argmax(axis=1)\n",
    "top1_sim = sims[np.arange(len(sims)), top1_idx]\n",
    "top2_sim = np.sort(sims, axis=1)[:, -2] if sims.shape[1] > 1 else np.zeros(len(sims))\n",
    "margin = top1_sim - top2_sim\n",
    "\n",
    "unknown_df[\"new_template\"] = [templates[i] for i in top1_idx]\n",
    "unknown_df[\"text_sim_top1\"] = top1_sim\n",
    "unknown_df[\"text_margin\"] = margin\n",
    "\n",
    "\n",
    "# See which threshold is the best\n",
    "def reassigned_rate(sim_min, margin_min):\n",
    "    m = (unknown_df[\"text_sim_top1\"] >= sim_min) & (unknown_df[\"text_margin\"] >= margin_min)\n",
    "    return m.mean(), m.sum()\n",
    "\n",
    "for sim_min in [0.70, 0.68, 0.66, 0.64, 0.62, 0.60, 0.58]:\n",
    "    for margin_min in [0.08, 0.06, 0.04, 0.02, 0.00]:\n",
    "        rate, cnt = reassigned_rate(sim_min, margin_min)\n",
    "        print(f\"SIM_MIN={sim_min:.2f}, MARGIN_MIN={margin_min:.2f} -> reassigned {cnt} ({rate*100:.1f}%)\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(unknown_df[\"text_sim_top1\"], bins=50)\n",
    "plt.title(\"Distribution of top-1 cosine similarity (NO_TEMPLATE)\")\n",
    "plt.xlabel(\"top-1 similarity\"); plt.ylabel(\"count\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(unknown_df[\"text_margin\"], bins=50)\n",
    "plt.title(\"Distribution of top-1 margin over top-2 (NO_TEMPLATE)\")\n",
    "plt.xlabel(\"margin\"); plt.ylabel(\"count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0815985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the threshold, static for now\n",
    "SIM_MIN = 0.68\n",
    "MARGIN_MIN = 0.04\n",
    "\n",
    "unknown_df[\"final_from_text\"] = np.where(\n",
    "    (unknown_df[\"text_sim_top1\"] >= SIM_MIN) & (unknown_df[\"text_margin\"] >= MARGIN_MIN),\n",
    "    unknown_df[\"new_template\"],\n",
    "    NO_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d179938",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_reassigned_df_updated = work_df.merge(\n",
    "    unknown_df[[KEY_COL, \"final_from_text\", \"text_sim_top1\", \"text_margin\"]],\n",
    "    on=KEY_COL, how=\"left\"\n",
    ")\n",
    "\n",
    "text_reassigned_df_updated[\"final_template\"] = np.where(\n",
    "    text_reassigned_df_updated[LABEL_COL] == NO_TEMPLATE,\n",
    "    text_reassigned_df_updated[\"final_from_text\"].fillna(NO_TEMPLATE),\n",
    "    text_reassigned_df_updated[LABEL_COL]\n",
    ")\n",
    "\n",
    "no_template_df_text = text_reassigned_df_updated[text_reassigned_df_updated[\"final_template\"] == NO_TEMPLATE]\n",
    "template_df_text    = text_reassigned_df_updated[text_reassigned_df_updated[\"final_template\"] != NO_TEMPLATE]\n",
    "\n",
    "ratio_no_template_text = no_template_df_text.shape[0] / text_reassigned_df_updated.shape[0] * 100\n",
    "\n",
    "print(f\"Number of 'NO_TEMPLATE' memes after text reassignment: {no_template_df_text.shape[0]}\")\n",
    "print(f\"Number of templated memes after text reassignment: {template_df_text.shape[0]}\")\n",
    "print(f'\"NO_TEMPLATE\" contains {ratio_no_template_text:.2f}% of the dataset after text reassignment')\n",
    "\n",
    "\n",
    "sizes = [no_template_df_text.shape[0], template_df_text.shape[0]]\n",
    "labels = [\"NO_TEMPLATE\", \"Has template\"]\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie(sizes, labels=labels, autopct=\"%1.1f%%\", startangle=90)\n",
    "plt.title(\"Template coverage after text reassignment\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff87102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save two df to csv to avoid re-runs\n",
    "# text_reassigned_df_updated.to_csv('data/text_reassigned_memes.csv', index=False)\n",
    "# image_reassigned_df_updated.to_csv('data/image_reassigned_memes.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4343b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) merge text-based reassignment as text_template\n",
    "meme_data_df = meme_data_df.merge(\n",
    "    text_reassigned_df_updated.rename(columns={\"final_template\": \"text_template\"}),\n",
    "    on=\"key\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 2) merge image-based reassignment as img_template\n",
    "meme_data_df = meme_data_df.merge(\n",
    "    image_reassigned_df_updated.rename(columns={\"template\": \"img_template\"}),\n",
    "    on=\"key\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "meme_data_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "working-env-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
